<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 5 MACHINE LEARNING (Supervisado) | Taller de Introducción a Ciencia de Datos y Machine Learning</title>
  <meta name="description" content="AMAT Curso 1 : Introduccion a Ciencia de Datos" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 5 MACHINE LEARNING (Supervisado) | Taller de Introducción a Ciencia de Datos y Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="AMAT Curso 1 : Introduccion a Ciencia de Datos" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 5 MACHINE LEARNING (Supervisado) | Taller de Introducción a Ciencia de Datos y Machine Learning" />
  
  <meta name="twitter:description" content="AMAT Curso 1 : Introduccion a Ciencia de Datos" />
  

<meta name="author" content="Karina Lizette Gamboa Puente" />
<meta name="author" content="Oscar Arturo Bringas López" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="explora.html"/>
<link rel="next" href="muestreo.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="img/conac-logo.png" width="280"></a></li|

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> BIENVENIDA</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i><b>1.1</b> Objetivo</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#quienes-somos"><i class="fa fa-check"></i><b>1.2</b> ¿Quienes somos?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> INTRODUCCIÓN</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#qué-es-ciencia-de-datos"><i class="fa fa-check"></i><b>2.1</b> ¿Qué es Ciencia de Datos?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="intro.html"><a href="intro.html#definiendo-conceptos"><i class="fa fa-check"></i><b>2.1.1</b> Definiendo conceptos:</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#objetivo-de-la-ciencia-se-datos"><i class="fa fa-check"></i><b>2.2</b> Objetivo de la Ciencia se Datos</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#qué-se-requiere-para-hacer-ciencia-de-datos"><i class="fa fa-check"></i><b>2.3</b> ¿Qué se requiere para hacer Ciencia de Datos?</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#tipos-de-problemas-que-se-pueden-resolver-con-ciencia-de-datos"><i class="fa fa-check"></i><b>2.4</b> Tipos de problemas que se pueden resolver con Ciencia de Datos</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#tipos-de-aprendizaje"><i class="fa fa-check"></i><b>2.5</b> Tipos de aprendizaje</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="intro.html"><a href="intro.html#aprendizaje-supervisado"><i class="fa fa-check"></i><b>2.5.1</b> Aprendizaje supervisado</a></li>
<li class="chapter" data-level="2.5.2" data-path="intro.html"><a href="intro.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>2.5.2</b> Aprendizaje no supervisado</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ciclo.html"><a href="ciclo.html"><i class="fa fa-check"></i><b>3</b> CICLO DE VIDA</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ciclo.html"><a href="ciclo.html#ciclo-de-un-proyecto-de-ciencia-de-datos"><i class="fa fa-check"></i><b>3.1</b> Ciclo de un proyecto de Ciencia de Datos</a></li>
<li class="chapter" data-level="3.2" data-path="ciclo.html"><a href="ciclo.html#data-science-scoping"><i class="fa fa-check"></i><b>3.2</b> Data Science <em>scoping</em></a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ciclo.html"><a href="ciclo.html#data-maturity-framework"><i class="fa fa-check"></i><b>3.2.1</b> Data Maturity Framework</a></li>
<li class="chapter" data-level="3.2.2" data-path="ciclo.html"><a href="ciclo.html#scoping"><i class="fa fa-check"></i><b>3.2.2</b> Scoping</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="explora.html"><a href="explora.html"><i class="fa fa-check"></i><b>4</b> ANÁLISIS EXPLORATORIO</a>
<ul>
<li class="chapter" data-level="4.1" data-path="explora.html"><a href="explora.html#análisis-exploratorio-de-datos-eda"><i class="fa fa-check"></i><b>4.1</b> Análisis Exploratorio de Datos (EDA)</a></li>
<li class="chapter" data-level="4.2" data-path="explora.html"><a href="explora.html#eda-análisis-exploratorio-de-datos"><i class="fa fa-check"></i><b>4.2</b> EDA: Análisis Exploratorio de Datos</a></li>
<li class="chapter" data-level="4.3" data-path="explora.html"><a href="explora.html#geda-análisis-exploratorio-de-datos-gráficos"><i class="fa fa-check"></i><b>4.3</b> GEDA: Análisis Exploratorio de Datos Gráficos</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="explora.html"><a href="explora.html#lo-que-no-se-debe-hacer"><i class="fa fa-check"></i><b>4.3.1</b> Lo que no se debe hacer…</a></li>
<li class="chapter" data-level="4.3.2" data-path="explora.html"><a href="explora.html#principios-de-visualización"><i class="fa fa-check"></i><b>4.3.2</b> Principios de visualización</a></li>
<li class="chapter" data-level="4.3.3" data-path="explora.html"><a href="explora.html#principios-generales-del-diseño-analítico"><i class="fa fa-check"></i><b>4.3.3</b> Principios generales del diseño analítico:</a></li>
<li class="chapter" data-level="4.3.4" data-path="explora.html"><a href="explora.html#técnicas-de-visualización"><i class="fa fa-check"></i><b>4.3.4</b> Técnicas de visualización:</a></li>
<li class="chapter" data-level="4.3.5" data-path="explora.html"><a href="explora.html#indicadores-de-calidad-gráfica"><i class="fa fa-check"></i><b>4.3.5</b> Indicadores de calidad gráfica:</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="explora.html"><a href="explora.html#uso-decisión-e-implementación-de-técnicas-gráficas."><i class="fa fa-check"></i><b>4.4</b> Uso, decisión e implementación de técnicas gráficas.</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="explora.html"><a href="explora.html#gráficos-univariados"><i class="fa fa-check"></i><b>4.4.1</b> Gráficos univariados:</a></li>
<li class="chapter" data-level="4.4.2" data-path="explora.html"><a href="explora.html#gráficos-multivariados"><i class="fa fa-check"></i><b>4.4.2</b> Gráficos multivariados</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="explora.html"><a href="explora.html#análisis-y-visualización-con-r"><i class="fa fa-check"></i><b>4.5</b> Análisis y Visualización con R</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="explora.html"><a href="explora.html#análisis-estadístico"><i class="fa fa-check"></i><b>4.5.1</b> Análisis estadístico</a></li>
<li class="chapter" data-level="4.5.2" data-path="explora.html"><a href="explora.html#análisis-gráfico-de-datos"><i class="fa fa-check"></i><b>4.5.2</b> Análisis Gráfico de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="modela.html"><a href="modela.html"><i class="fa fa-check"></i><b>5</b> MACHINE LEARNING (Supervisado)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="modela.html"><a href="modela.html#ml-y-algoritmos"><i class="fa fa-check"></i><b>5.1</b> ML y Algoritmos</a></li>
<li class="chapter" data-level="5.2" data-path="modela.html"><a href="modela.html#sesgo-vs-varianza"><i class="fa fa-check"></i><b>5.2</b> Sesgo vs varianza</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="modela.html"><a href="modela.html#balance-entre-sesgo-y-varianza-o-trade-off"><i class="fa fa-check"></i><b>5.2.1</b> Balance entre sesgo y varianza o Trade-off</a></li>
<li class="chapter" data-level="5.2.2" data-path="modela.html"><a href="modela.html#overfitting"><i class="fa fa-check"></i><b>5.2.2</b> Overfitting</a></li>
<li class="chapter" data-level="5.2.3" data-path="modela.html"><a href="modela.html#underfitting"><i class="fa fa-check"></i><b>5.2.3</b> Underfitting</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="modela.html"><a href="modela.html#estimación-de-errores"><i class="fa fa-check"></i><b>5.3</b> Estimación de errores</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="modela.html"><a href="modela.html#errores-reducibles"><i class="fa fa-check"></i><b>5.3.1</b> Errores reducibles</a></li>
<li class="chapter" data-level="5.3.2" data-path="modela.html"><a href="modela.html#error-irreducible"><i class="fa fa-check"></i><b>5.3.2</b> Error irreducible</a></li>
<li class="chapter" data-level="5.3.3" data-path="modela.html"><a href="modela.html#error-total"><i class="fa fa-check"></i><b>5.3.3</b> Error total</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="modela.html"><a href="modela.html#partición-de-datos"><i class="fa fa-check"></i><b>5.4</b> Partición de datos</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="modela.html"><a href="modela.html#métodos-comunes-para-particionar-datos"><i class="fa fa-check"></i><b>5.4.1</b> Métodos comunes para particionar datos</a></li>
<li class="chapter" data-level="5.4.2" data-path="modela.html"><a href="modela.html#qué-proporción-debería-ser-usada"><i class="fa fa-check"></i><b>5.4.2</b> ¿Qué proporción debería ser usada?</a></li>
<li class="chapter" data-level="5.4.3" data-path="modela.html"><a href="modela.html#conjunto-de-validación"><i class="fa fa-check"></i><b>5.4.3</b> Conjunto de validación</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="modela.html"><a href="modela.html#métricas-de-desempeño-y-estimación-de-errores"><i class="fa fa-check"></i><b>5.5</b> Métricas de desempeño y estimación de errores</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="modela.html"><a href="modela.html#métricas-de-desempeño-para-clasificación"><i class="fa fa-check"></i><b>5.5.1</b> Métricas de desempeño para clasificación</a></li>
<li class="chapter" data-level="5.5.2" data-path="modela.html"><a href="modela.html#implementación-con-r"><i class="fa fa-check"></i><b>5.5.2</b> Implementación con R</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="modela.html"><a href="modela.html#algotitmos-de-machine-learning"><i class="fa fa-check"></i><b>5.6</b> Algotitmos de machine learning</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="modela.html"><a href="modela.html#regresión-logística"><i class="fa fa-check"></i><b>5.6.1</b> Regresión logística</a></li>
<li class="chapter" data-level="5.6.2" data-path="modela.html"><a href="modela.html#knn-k-nearest-neighbor"><i class="fa fa-check"></i><b>5.6.2</b> KNN: K-Nearest-Neighbor</a></li>
<li class="chapter" data-level="5.6.3" data-path="modela.html"><a href="modela.html#árboles-de-decisión-decision-trees"><i class="fa fa-check"></i><b>5.6.3</b> Árboles de decisión (Decision trees)</a></li>
<li class="chapter" data-level="5.6.4" data-path="modela.html"><a href="modela.html#bagging"><i class="fa fa-check"></i><b>5.6.4</b> Bagging</a></li>
<li class="chapter" data-level="5.6.5" data-path="modela.html"><a href="modela.html#random-forest"><i class="fa fa-check"></i><b>5.6.5</b> Random Forest</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="muestreo.html"><a href="muestreo.html"><i class="fa fa-check"></i><b>6</b> DISEÑO DE EXPERIMENTOS</a>
<ul>
<li class="chapter" data-level="6.1" data-path="muestreo.html"><a href="muestreo.html#diseño-de-experimentos-para-machine-learning"><i class="fa fa-check"></i><b>6.1</b> Diseño de experimentos para Machine Learning</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="muestreo.html"><a href="muestreo.html#por-qué-hacer-un-experimento"><i class="fa fa-check"></i><b>6.1.1</b> ¿Por qué hacer un experimento?</a></li>
<li class="chapter" data-level="6.1.2" data-path="muestreo.html"><a href="muestreo.html#ab-testing"><i class="fa fa-check"></i><b>6.1.2</b> A/B Testing</a></li>
<li class="chapter" data-level="6.1.3" data-path="muestreo.html"><a href="muestreo.html#qué-es-y-para-qué-sirve-muestreo"><i class="fa fa-check"></i><b>6.1.3</b> ¿Qué es y para qué sirve muestreo?</a></li>
<li class="chapter" data-level="6.1.4" data-path="muestreo.html"><a href="muestreo.html#ventajas-del-muestreo-en-el-mundo-corporativo"><i class="fa fa-check"></i><b>6.1.4</b> Ventajas del muestreo en el mundo corporativo</a></li>
<li class="chapter" data-level="6.1.5" data-path="muestreo.html"><a href="muestreo.html#qué-se-requiere-para-formular-un-problema-de-muestreo"><i class="fa fa-check"></i><b>6.1.5</b> ¿Qué se requiere para formular un problema de muestreo?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="muestreo.html"><a href="muestreo.html#muestreo-probabilístico"><i class="fa fa-check"></i><b>6.2</b> Muestreo probabilístico</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="agrupa.html"><a href="agrupa.html"><i class="fa fa-check"></i><b>7</b> MACHINE LEARNING (No Supervisado)</a>
<ul>
<li class="chapter" data-level="7.1" data-path="agrupa.html"><a href="agrupa.html#clustering"><i class="fa fa-check"></i><b>7.1</b> Clustering</a></li>
<li class="chapter" data-level="7.2" data-path="agrupa.html"><a href="agrupa.html#k---means"><i class="fa fa-check"></i><b>7.2</b> K - means</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="agrupa.html"><a href="agrupa.html#ajuste-de-modelo-cómo-funciona-el-algortimo"><i class="fa fa-check"></i><b>7.2.1</b> Ajuste de modelo: ¿Cómo funciona el algortimo?</a></li>
<li class="chapter" data-level="7.2.2" data-path="agrupa.html"><a href="agrupa.html#implementación-en-r"><i class="fa fa-check"></i><b>7.2.2</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="agrupa.html"><a href="agrupa.html#partitioning-around-medoids-pam"><i class="fa fa-check"></i><b>7.3</b> Partitioning Around Medoids (PAM)</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="agrupa.html"><a href="agrupa.html#implementación-en-r-1"><i class="fa fa-check"></i><b>7.3.1</b> Implementación en R</a></li>
<li class="chapter" data-level="7.3.2" data-path="agrupa.html"><a href="agrupa.html#algoritmo-pam"><i class="fa fa-check"></i><b>7.3.2</b> Algoritmo PAM</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="agrupa.html"><a href="agrupa.html#dbscan"><i class="fa fa-check"></i><b>7.4</b> DBSCAN</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="agrupa.html"><a href="agrupa.html#algoritmo"><i class="fa fa-check"></i><b>7.4.1</b> Algoritmo</a></li>
<li class="chapter" data-level="7.4.2" data-path="agrupa.html"><a href="agrupa.html#implementación-en-r-2"><i class="fa fa-check"></i><b>7.4.2</b> Implementación en R</a></li>
<li class="chapter" data-level="7.4.3" data-path="agrupa.html"><a href="agrupa.html#ventajas-de-dbscan"><i class="fa fa-check"></i><b>7.4.3</b> Ventajas de DBSCAN</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="otros.html"><a href="otros.html"><i class="fa fa-check"></i><b>8</b> OTRAS HERRAMIENTAS Y TECNOLOGÍAS</a>
<ul>
<li class="chapter" data-level="8.1" data-path="otros.html"><a href="otros.html#git-y-github"><i class="fa fa-check"></i><b>8.1</b> Git y Github</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="otros.html"><a href="otros.html#qué-es-git"><i class="fa fa-check"></i><b>8.1.1</b> <strong>¿Qué es Git?</strong></a></li>
<li class="chapter" data-level="8.1.2" data-path="otros.html"><a href="otros.html#qué-es-github"><i class="fa fa-check"></i><b>8.1.2</b> <strong>¿Qué es Github?</strong></a></li>
<li class="chapter" data-level="8.1.3" data-path="otros.html"><a href="otros.html#cómo-utilizarlos"><i class="fa fa-check"></i><b>8.1.3</b> <strong>¿Cómo utilizarlos?</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="despedida.html"><a href="despedida.html"><i class="fa fa-check"></i><b>9</b> DESPEDIDA</a></li>
<li class="divider"></li>
<li><a href="./"><img src="img/amat-logo.png" width="280"></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Taller de Introducción a Ciencia de Datos y Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modela" class="section level1" number="5">
<h1><span class="header-section-number">Capítulo 5</span> MACHINE LEARNING (Supervisado)</h1>
<div class="watermark">
<img src="img/header.png" width="400">
</div>
<div id="ml-y-algoritmos" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> ML y Algoritmos</h2>
<p>Como se habia mencionado, el Machine Learning es una disciplina del campo de la Inteligencia Artificial que, a través de algoritmos, dota a los ordenadores de la capacidad de identificar patrones en datos para hacer predicciones. Este aprendizaje permite a los computadores realizar tareas específicas de forma autónoma.</p>
<p>El término se utilizó por primera vez en 1959. Sin embargo, ha ganado relevancia en los últimos años debido al aumento de la capacidad de computación y al <em>BOOM</em> de los datos.</p>
<p>Un algoritmo para computadoras puede ser pensado como una receta. Describe exactamente qué pasos se realizan uno tras otro. Los ordenadores no entienden las recetas de cocina, sino los lenguajes de programación: En ellos, el algoritmo se descompone en pasos formales (comandos) que el ordenador puede entender.</p>
<p><img src="img/ml/WebQuest.gif" width="400pt" style="display: block; margin: auto;" /></p>
<p>Algunos problemas pueden formularse fácilmente como un algoritmo, por ejemplo, contando del 1 al 100 o comprobando si un número es un número primo. Para otros problemas, esto es muy difícil, por ejemplo, reconocer la escritura o el texto de las teclas. Aquí los procedimientos de aprendizaje de la máquina ayudan. Durante mucho tiempo se han desarrollado algoritmos que permiten analizar los datos existentes y aplicar los conocimientos derivados de ello a los nuevos datos.</p>
<p>La cuestión no es solo saber para qué sirve el Machine Learning, sino que saber cómo funciona y cómo poder implementarlo en la industria para aprovecharse de sus beneficios.
Hay ciertos pasos que usualmente se siguen para crear un modelo de Machine Learning. Estos son típicamente realizados por científicos de los datos que trabajan en estrecha colaboración con los profesionales de los negocios para los que se está desarrollando el modelo.</p>
<ul>
<li><strong>Seleccionar y preparar un conjunto de datos de entrenamiento</strong></li>
</ul>
<p>Los <strong>datos de entrenamiento</strong> son un conjunto de datos representativos de los datos que el modelo de Machine Learning ingerirá para resolver el problema que está diseñado para resolver.</p>
<p>Los datos de entrenamiento deben prepararse adecuadamente: aleatorizados y comprobados en busca de desequilibrios o sesgos que puedan afectar al entrenamiento. También deben dividirse en dos subconjuntos: el <strong>subconjunto de entrenamiento</strong>, que se utilizará para entrenar el algoritmo, y el <strong>subconjunto de validación</strong>, que se utilizará para probarlo y perfeccionarlo.</p>
<p><img src="img/ml/train-and-test.png" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Elegir un algoritmo para ejecutarlo en el conjunto de datos de entrenamiento</strong></li>
</ul>
<p>Este es uno de los pasos más importantes, ya que se debe elegir qué algoritmo utilizar, siendo este un conjunto de pasos de procesamiento estadístico. El tipo de algoritmo depende del tipo (supervisado o no supervisado), la cantidad de datos del conjunto de datos de entrenamiento y del tipo de problema que se debe resolver.</p>
<p><img src="img/ml/modelos.jpg" width="600pt" style="display: block; margin: auto;" /></p>
<p><img src="img/ml/armas-modelos.jpg" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Entrenamiento del algoritmo para crear el modelo</strong></li>
</ul>
<p>El entrenamiento del algoritmo es un proceso iterativo: implica ejecutar las variables a través del algoritmo, comparar el resultado con los resultados que debería haber producido, ajustar los pesos y los sesgos dentro del algoritmo que podrían dar un resultado más exacto, y ejecutar las variables de nuevo hasta que el algoritmo devuelva el resultado correcto la mayoría de las veces. El algoritmo resultante, entrenado y preciso, es el modelo de Machine Learning.</p>
<p><img src="img/ml/entrenamiento.jpg" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li>Usar y mejorar el modelo</li>
</ul>
<p>El paso final es utilizar el modelo con nuevos datos y, en el mejor de los casos, para que mejore en precisión y eficacia con el tiempo. De dónde procedan los nuevos datos dependerá del problema que se resuelva. Por ejemplo, un modelo de Machine Learning diseñado para identificar el spam ingerirá mensajes de correo electrónico, mientras que un modelo de Machine Learning que maneja una aspiradora robot ingerirá datos que resulten de la interacción en el mundo real con muebles movidos o nuevos objetos en la habitación.</p>
<p><img src="img/ml/competencia.jpg" width="600pt" style="display: block; margin: auto;" /></p>
</div>
<div id="sesgo-vs-varianza" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Sesgo vs varianza</h2>
<p>En el mundo de Machine Learning cuando desarrollamos un modelo nos esforzamos para hacer que sea lo más preciso, ajustando los parámetros, pero la realidad es que no se puede construir un modelo 100% preciso ya que nunca pueden estar libres de errores.</p>
<p>Comprender cómo las diferentes fuentes de error generan sesgo y varianza nos ayudará a mejorar el proceso de ajuste de datos, lo que resulta en modelos más precisos, adicionalmente también evitará el error de sobreajuste y falta de ajuste.</p>
<div id="balance-entre-sesgo-y-varianza-o-trade-off" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Balance entre sesgo y varianza o Trade-off</h3>
<p>El objetivo de cualquier algoritmo supervisado de Machine Learning es lograr un bias bajo, una baja varianza y a su vez el algoritmo debe lograr un buen rendimiento de predicción.</p>
<p><img src="img/ml/3-1-3-tradeoff.jpeg" width="650pt" height="450pt" style="display: block; margin: auto;" /></p>
<p>El bias frente a la varianza se refiere a la precisión frente a la consistencia de los modelos entrenados por su algoritmo. Podemos diagnosticarlos de la siguiente manera:</p>
<p><img src="img/ml/3-1-3-altobias.jpeg" width="650pt" height="350pt" style="display: block; margin: auto;" /></p>
<p>Los algoritmos de baja varianza (alto bias) tienden a ser menos complejos, con una estructura subyacente simple o rígida.</p>
<p><img src="img/ml/3-1-3-bajobias.jpeg" width="650pt" height="350pt" style="display: block; margin: auto;" /></p>
<p>Los algoritmos de bajo bias (alta varianza) tienden a ser más complejos, con una estructura subyacente flexible.</p>
<p>No hay escapatoria a la relación entre el bias y la varianza en Machine Learning, aumentar el bias disminuirá la varianza, aumentar la varianza disminuirá el bias.</p>
</div>
<div id="overfitting" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Overfitting</h3>
<ul>
<li><p>El modelo es muy particular.</p></li>
<li><p>Error debido a la varianza</p></li>
<li><p>Durante el entrenamiento tiene un desempeño muy bueno, pero al pasar nuevos datos su desempeño es malo.</p></li>
</ul>
</div>
<div id="underfitting" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Underfitting</h3>
<ul>
<li><p>El modelo es demasiado general.</p></li>
<li><p>Error debido al sesgo.</p></li>
<li><p>Durante el entrenamiento no tiene un buen desempeño.</p></li>
</ul>
<p><img src="img/ml/over-under.jpg" width="600pt" height="350pt" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="estimación-de-errores" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Estimación de errores</h2>
<div id="errores-reducibles" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Errores reducibles</h3>
<ul>
<li><strong>Error por sesgo:</strong></li>
</ul>
<p>Es la diferencia entre la predicción esperada de nuestro modelo y los valores verdaderos. Aunque al final nuestro objetivo es siempre construir modelos que puedan predecir datos muy cercanos a los valores verdaderos, no siempre es tan fácil porque algunos algoritmos son simplemente demasiado rígidos para aprender señales complejas del conjunto de datos.</p>
<p>Imagina ajustar una regresión lineal a un conjunto de datos que tiene un patrón no lineal, no importa cuántas observaciones más recopiles, una regresión lineal no podrá modelar las curvas en esos datos. Esto se conoce como <em>underfitting</em>.</p>
<ul>
<li><strong>Error por varianza:</strong></li>
</ul>
<p>Se refiere a la cantidad que la estimación de la función objetivo cambiará si se utiliza diferentes datos de entrenamiento. La función objetivo se estima a partir de los datos de entrenamiento mediante un algoritmo de Machine Learning, por lo que deberíamos esperar que el algoritmo tenga alguna variación. Idealmente no debería cambiar demasiado de un conjunto de datos de entrenamiento a otro.</p>
<p><img src="img/ml/3-1-3-biasvar.png" width="650pt" height="350pt" style="display: block; margin: auto;" /></p>
<p>Los algoritmos de Machine Learning que tienen una gran varianza están fuertemente influenciados por los detalles de los datos de entrenamiento, esto significa que los detalles de la capacitación influyen en el número y los tipos de parámetros utilizados para caracterizar la función de mapeo.</p>
</div>
<div id="error-irreducible" class="section level3" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Error irreducible</h3>
<p>El error irreducible no se puede reducir, independientemente de qué algoritmo se usa. También se le conoce como ruido y, por lo general, proviene por factores como variables desconocidas que influyen en el mapeo de las variables de entrada a la variable de salida, un conjunto de características incompleto o un problema mal enmarcado. Acá es importante comprender que no importa cuán bueno hagamos nuestro modelo, nuestros datos tendrán cierta cantidad de ruido o un error irreductible que no se puede eliminar.</p>
</div>
<div id="error-total" class="section level3" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Error total</h3>
<p>Comprender el sesgo y la varianza es fundamental para comprender el comportamiento de los modelos de predicción, pero en general lo que realmente importa es el error general, no la descomposición específica. El punto ideal para cualquier modelo es el nivel de complejidad en el que el aumento en el sesgo es equivalente a la reducción en la varianza.</p>
<p><img src="img/ml/3-1-3-errortotal.jpeg" width="650pt" height="450pt" style="display: block; margin: auto;" /></p>
<p>Para construir un buen modelo, necesitamos encontrar un buen equilibrio entre el bias y la varianza de manera que minimice el error total.</p>
<p>Un equilibrio óptimo de bias y varianza nunca sobreequiparía o no sería adecuado para el modelo. Por lo tanto comprender el sesgo y la varianza es fundamental para comprender el comportamiento de los modelos de predicción.</p>
</div>
</div>
<div id="partición-de-datos" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Partición de datos</h2>
<p><img src="img/ml/3-5-particion-datos.jpg" width="150pt" height="150pt" style="display: block; margin: auto auto auto 0;" /></p>
<p>Cuando hay una gran cantidad de datos disponibles, una estrategia inteligente es asignar subconjuntos específicos de datos para diferentes tareas, en lugar de asignar la mayor cantidad posible solo a la estimación de los parámetros del modelo.</p>
<p>Si el conjunto inicial de datos no es lo suficientemente grande, habrá cierta superposición
de cómo y cuándo se asignan nuestros datos, y es importante contar con una metodología
sólida para la partición de datos.</p>
<div id="métodos-comunes-para-particionar-datos" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Métodos comunes para particionar datos</h3>
<p>El enfoque principal para la validación del modelo es dividir el conjunto de datos existente en dos conjuntos distintos:</p>
<ul>
<li><p><strong>Entrenamiento:</strong> Este conjunto suele contener la mayoría de los datos, los cuales
sirven para la construcción de modelos donde se pueden ajustar diferentes modelos,
se investigan estrategias de ingeniería de características, etc.</p>
<p>La mayor parte del proceso de modelado se utiliza este conjunto.</p></li>
<li><p><strong>Prueba:</strong> La otra parte de las observaciones se coloca en este conjunto.
Estos datos se mantienen en reserva hasta que se elijan uno o dos modelos como los de mejor rendimiento.</p>
<p>El conjunto de prueba se utiliza como árbitro final para determinar la eficiencia del modelo,
por lo que es fundamental mirar el conjunto de prueba una sola vez.</p></li>
</ul>
</div>
<div id="qué-proporción-debería-ser-usada" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> ¿Qué proporción debería ser usada?</h3>
<p>No hay un porcentaje de división óptimo para el conjunto de entrenamiento y prueba.
Muy pocos datos en el conjunto de entrenamiento obstaculizan la capacidad del modelo para encontrar estimaciones de parámetros adecuadas y muy pocos datos en el conjunto de prueba reducen la calidad de las estimaciones de rendimiento.</p>
<p>Se debe elegir un porcentaje que cumpla con los objetivos de nuestro proyecto con consideraciones que incluyen:</p>
<ul>
<li>Costo computacional en el entrenamiento del modelo.</li>
<li>Costo computacional en la evaluación del modelo.</li>
<li>Representatividad del conjunto de formación.</li>
<li>Representatividad del conjunto de pruebas.</li>
</ul>
<p>Los porcentajes de división más comunes comunes son:</p>
<ul>
<li>Entrenamiento: <span class="math inline">\(80\%\)</span>, Prueba: <span class="math inline">\(20\%\)</span></li>
<li>Entrenamiento: <span class="math inline">\(67\%\)</span>, Prueba: <span class="math inline">\(33\%\)</span></li>
<li>Entrenamiento: <span class="math inline">\(50\%\)</span>, Prueba: <span class="math inline">\(50\%\)</span></li>
</ul>
</div>
<div id="conjunto-de-validación" class="section level3" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Conjunto de validación</h3>
<p>El conjunto de validación se definió originalmente cuando los investigadores se dieron cuenta de que medir el rendimiento del conjunto de entrenamiento conducía a resultados que eran demasiado optimistas.</p>
<p>Esto llevó a modelos que se sobreajustaban, lo que significa que se desempeñaron muy bien en el conjunto de entrenamiento pero mal en el conjunto de prueba.</p>
<p>Para combatir este problema, se retuvo un pequeño conjunto de datos de <em>validación</em> y se utilizó para medir el rendimiento del modelo mientras este está siendo entrenado. Una vez que la tasa de error del conjunto de validación comenzara a aumentar, la capacitación se detendría.</p>
<p>En otras palabras, el conjunto de validación es un medio para tener una idea aproximada de qué tan bien se desempeñó el modelo antes del conjunto de prueba.</p>
<p><img src="img/ml/3-5-3-conjunto-validacion.png" width="500pt" height="250pt" style="display: block; margin: auto;" /></p>
<p>Los conjuntos de validación se utilizan a menudo cuando el conjunto de datos original es muy grande. En este caso, una sola partición grande puede ser adecuada para caracterizar el rendimiento del modelo sin tener que realizar múltiples iteraciones de remuestreo.</p>
<p><img src="img/ml/3-5-3-conjunto-validacion-2.png" width="500pt" height="350pt" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="métricas-de-desempeño-y-estimación-de-errores" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Métricas de desempeño y estimación de errores</h2>
<p>Hasta ahora ya se ha visto cual es el proceso que debe llevar un modelo de Machine Learning y si bien, el alcance, la manera de preparar los datos, la elección de los algoritmos y el entrenamiento son partes clave, es igualmente importante medir el rendimiento del modelo entrenado.
Al utilizar diferentes métricas para la evaluación del rendimiento, deberíamos estar en posición de detectar algún problema o de mejorar el poder de predicción general de nuestro modelo antes de que lo pongamos en producción.</p>
<div id="métricas-de-desempeño-para-clasificación" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Métricas de desempeño para clasificación</h3>
<p>Existen distintas métricas de desempeño para problemas de clasificación, debido a que contamos con la respuesta correcta podemos contar cuántos aciertos tuvimos y cuántos fallos tuvimos.</p>
<p>Primero, por simplicidad ocuparemos un ejemplo de clasificación binaria, Fraude (1) o No fraude (0).</p>
<p>En este tipo de algoritmos definimos cuál de las categorías será nuestra etiqueta positiva y cuál será la negativa. La positiva será la categoría que queremos predecir -en nuestro ejemplo, fraude- y la negativa lo opuesto -en el caso binario- en nuestro ejemplo, no fraude.</p>
<p>Dadas estas definiciones tenemos 4 posibilidades:</p>
<ul>
<li><p><strong>True positives</strong>: Nuestra predicción dijo que la transacción es fraude y la etiqueta real dice que es fradue.</p></li>
<li><p><strong>False positives</strong>: Nuestra predicción dijo que la transacción es fraude y la etiqueta real dice que no es fraude.</p></li>
<li><p><strong>True negatives</strong>: Nuestra predicción dijo que la transacción es no fraude y la etiqueta real dice que no es fraude.</p></li>
<li><p><strong>False negatives</strong>: Nuestra predicción dijo que la transacción es no fraude y la etiqueta real dice que es fraude.</p></li>
<li><p><strong>Matriz de confusión</strong></p></li>
</ul>
<p><img src="img/ml/3-8-4-confusion.png" width="700pt" height="250pt" style="display: block; margin: auto;" /></p>
<p>Esta métrica corresponde a una matriz en donde se plasma el conteo de los aciertos y los errores que haya hecho el modelo.</p>
<p>En esta métrica utilizamos todos los aciertos y todos los errores que haya tenido el modelo en las predicciones, esto es: los verdaderos positivos (TP), los verdaderos negativos (TN), los falsos positivos (FP) y los falsos negativos (FN).</p>
<p>Normalmente los renglones representan las etiquetas reales, ya sean positivas o negativas, y las columnas, las etiquetas predichas.</p>
<ul>
<li><strong>Accuracy</strong></li>
</ul>
<p>Número de aciertos totales entre todas las predicciones.</p>
<p><span class="math display">\[accuracy = \frac{TP + TN}{ TP+FP+TN+FN}\]</span></p>
<p>La métrica más utilizada, en datasets imbalanceados esta métrica no nos sirve, al contrario, nos engaña.</p>
<ul>
<li><strong>Precision</strong>: Eficiencia</li>
</ul>
<p>De los que identificamos como clase positiva, cuántos identificamos correctamente. ¿Qué tan eficientes somos en la predicción?</p>
<p><span class="math display">\[precision = \frac{TP}{TP + FP}\]</span></p>
<p>¿Cuándo utilizar precision?</p>
<p>Esta es la métrica que ocuparás más, pues en un contexto de negocio, donde los recursos son finitos y tiene un costo asociado, ya sea monetario o de tiempo o de recursos, necesitarás que las predicciones de tu etiqueta positiva sean muy eficientes.</p>
<p>Al utilizar esta métrica estaremos optimizando el modelo para minimizar el número de falsos positivos.</p>
<ul>
<li><strong>Recall o Sensibilidad</strong>: Cobertura</li>
</ul>
<p>Del universo posible de nuestra clase positiva, cuántos identificamos correctamente.</p>
<p><span class="math display">\[recall = \frac{TP}{TP + FN }\]</span></p>
<p>Esta métrica la ocuparás cuando en el contexto de negocio de tu problema sea más conveniente minimizar los falsos negativos por el impacto que estos pueden tener en las personas en quienes se implementará la predicción.</p>
<p>Al utilizar esta métrica estaremos optimizando el modelo para minimizar el número de falsos negativos.</p>
<ul>
<li><strong>Especificidad</strong></li>
</ul>
<p>Es el número de observaciones correctamente identificados como negativos fuera del total de negativos.</p>
<p><span class="math display">\[Specificity = \frac{TN}{TN+FP}\]</span></p>
<ul>
<li><strong>F1-score</strong></li>
</ul>
<p>Combina precision y recall para optimizar ambos.</p>
<p><span class="math display">\[F = 2 *\frac{precision * recall}{precision + recall} \]</span></p>
<p>Se recomienda utilizar esta métrica de desempeño cuando quieres balancear tanto los falsos positivos como los falsos negativos. Aunque es una buena solución para tomar en cuenta ambos errores, pocas veces hay problemas reales que permiten ocuparla, esto es porque en más del 90% de los casos tenemos una restricción en recursos.</p>
<p>Ahora con esto en mente podemos definir las siguientes métricas:</p>
<ul>
<li><strong>AUC y ROC</strong>: <em>Area Under the Curve y Receiver operator characteristic</em></li>
</ul>
<p><img src="img/ml/3-8-4-roc.png" width="700pt" height="400pt" style="display: block; margin: auto;" /></p>
<p>Una curva <strong>ROC</strong> es un gráfico que muestra el desempeño de un modelo de clasificación en todos los puntos de corte.</p>
<p><strong>AUC</strong> significa “Área bajo la curva ROC.” Es decir, <strong>AUC</strong> mide el área debajo de la curva ROC.</p>
</div>
<div id="implementación-con-r" class="section level3" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Implementación con R</h3>
<p>Vamos a analizar los resultados de varios modelos, ellos pueden encontrarlos en la carpeta de archivos del curso:
<a href="https://drive.google.com/drive/u/2/folders/1df2bI-3JCMpyCSQEEWCeSWoA9GI3VnBt">DATOS</a></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="modela.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb5-2"><a href="modela.html#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb5-3"><a href="modela.html#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="modela.html#cb5-4" aria-hidden="true" tabindex="-1"></a>predicted_data <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;data/predicted_data.rds&quot;</span>)</span>
<span id="cb5-5"><a href="modela.html#cb5-5" aria-hidden="true" tabindex="-1"></a>predicted_data <span class="sc">%&gt;%</span> <span class="fu">head</span>(<span class="dv">8</span>) <span class="sc">%&gt;%</span> knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code></pre></div>
<table style="width:100%;">
<colgroup>
<col width="2%" />
<col width="2%" />
<col width="1%" />
<col width="3%" />
<col width="2%" />
<col width="4%" />
<col width="2%" />
<col width="3%" />
<col width="2%" />
<col width="3%" />
<col width="4%" />
<col width="4%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="4%" />
<col width="4%" />
<col width="7%" />
<col width="4%" />
<col width="3%" />
<col width="1%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">.pred_No</th>
<th align="right">.pred_Yes</th>
<th align="left">truth</th>
<th align="left">customerID</th>
<th align="left">gender</th>
<th align="right">SeniorCitizen</th>
<th align="left">Partner</th>
<th align="left">Dependents</th>
<th align="right">tenure</th>
<th align="left">PhoneService</th>
<th align="left">MultipleLines</th>
<th align="left">InternetService</th>
<th align="left">OnlineSecurity</th>
<th align="left">OnlineBackup</th>
<th align="left">DeviceProtection</th>
<th align="left">TechSupport</th>
<th align="left">StreamingTV</th>
<th align="left">StreamingMovies</th>
<th align="left">Contract</th>
<th align="left">PaperlessBilling</th>
<th align="left">PaymentMethod</th>
<th align="right">MonthlyCharges</th>
<th align="right">TotalCharges</th>
<th align="left">Churn</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.9611667</td>
<td align="right">0.0388333</td>
<td align="left">No</td>
<td align="left">5575-GNVDE</td>
<td align="left">Male</td>
<td align="right">0</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="right">34</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">DSL</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">One year</td>
<td align="left">No</td>
<td align="left">Mailed check</td>
<td align="right">56.95</td>
<td align="right">1889.50</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="right">0.2345000</td>
<td align="right">0.7655000</td>
<td align="left">Yes</td>
<td align="left">9305-CDSKC</td>
<td align="left">Female</td>
<td align="right">0</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="right">8</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="left">Fiber optic</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="left">Month-to-month</td>
<td align="left">Yes</td>
<td align="left">Electronic check</td>
<td align="right">99.65</td>
<td align="right">820.50</td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="right">0.6030000</td>
<td align="right">0.3970000</td>
<td align="left">No</td>
<td align="left">6713-OKOMC</td>
<td align="left">Female</td>
<td align="right">0</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="right">10</td>
<td align="left">No</td>
<td align="left">No phone service</td>
<td align="left">DSL</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">Month-to-month</td>
<td align="left">No</td>
<td align="left">Mailed check</td>
<td align="right">29.75</td>
<td align="right">301.90</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="right">0.9960000</td>
<td align="right">0.0040000</td>
<td align="left">No</td>
<td align="left">7469-LKBCI</td>
<td align="left">Male</td>
<td align="right">0</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="right">16</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">Two year</td>
<td align="left">No</td>
<td align="left">Credit card (automatic)</td>
<td align="right">18.95</td>
<td align="right">326.80</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="right">0.9804167</td>
<td align="right">0.0195833</td>
<td align="left">No</td>
<td align="left">9959-WOFKT</td>
<td align="left">Male</td>
<td align="right">0</td>
<td align="left">No</td>
<td align="left">Yes</td>
<td align="right">71</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="left">Fiber optic</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="left">Two year</td>
<td align="left">No</td>
<td align="left">Bank transfer (automatic)</td>
<td align="right">106.70</td>
<td align="right">7382.25</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="right">0.3996667</td>
<td align="right">0.6003333</td>
<td align="left">No</td>
<td align="left">4183-MYFRB</td>
<td align="left">Female</td>
<td align="right">0</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="right">21</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">Fiber optic</td>
<td align="left">No</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">Yes</td>
<td align="left">Month-to-month</td>
<td align="left">Yes</td>
<td align="left">Electronic check</td>
<td align="right">90.05</td>
<td align="right">1862.90</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="right">0.9965833</td>
<td align="right">0.0034167</td>
<td align="left">No</td>
<td align="left">1680-VDCWW</td>
<td align="left">Male</td>
<td align="right">0</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="right">12</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">No internet service</td>
<td align="left">One year</td>
<td align="left">No</td>
<td align="left">Bank transfer (automatic)</td>
<td align="right">19.80</td>
<td align="right">202.25</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="right">0.7549167</td>
<td align="right">0.2450833</td>
<td align="left">No</td>
<td align="left">6322-HRPFA</td>
<td align="left">Male</td>
<td align="right">0</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="right">49</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">DSL</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">Yes</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">Month-to-month</td>
<td align="left">No</td>
<td align="left">Credit card (automatic)</td>
<td align="right">59.60</td>
<td align="right">2970.30</td>
<td align="left">No</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="modela.html#cb6-1" aria-hidden="true" tabindex="-1"></a>pr_curve_rforest_clas <span class="ot">&lt;-</span> predicted_data <span class="sc">%&gt;%</span> </span>
<span id="cb6-2"><a href="modela.html#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pr_curve</span>(<span class="at">truth =</span> truth, <span class="at">estimate =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span>)</span>
<span id="cb6-3"><a href="modela.html#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="modela.html#cb6-4" aria-hidden="true" tabindex="-1"></a>roc_curve_rforest_clas <span class="ot">&lt;-</span> predicted_data <span class="sc">%&gt;%</span> </span>
<span id="cb6-5"><a href="modela.html#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(<span class="at">truth =</span> truth, <span class="at">estimate =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="modela.html#cb7-1" aria-hidden="true" tabindex="-1"></a>roc_curve_rforest_clas <span class="sc">%&gt;%</span> </span>
<span id="cb7-2"><a href="modela.html#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb7-3"><a href="modela.html#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Curva ROC&quot;</span>) <span class="sc">+</span></span>
<span id="cb7-4"><a href="modela.html#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Tasa Falsos Positivos&quot;</span>) <span class="sc">+</span></span>
<span id="cb7-5"><a href="modela.html#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Cobertura&quot;</span>)</span></code></pre></div>
<p><img src="Taller-de--Introducci%C3%B3n-a-Ciencia-de-Datos-y-Machine-Learning-_files/figure-html/unnamed-chunk-70-1.png" width="672" /></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="modela.html#cb8-1" aria-hidden="true" tabindex="-1"></a>pr_curve_rforest_clas <span class="sc">%&gt;%</span> </span>
<span id="cb8-2"><a href="modela.html#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb8-3"><a href="modela.html#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Curva PR&quot;</span>) <span class="sc">+</span></span>
<span id="cb8-4"><a href="modela.html#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Cobertura&quot;</span>) <span class="sc">+</span></span>
<span id="cb8-5"><a href="modela.html#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Precisión&quot;</span>)</span></code></pre></div>
<p><img src="Taller-de--Introducci%C3%B3n-a-Ciencia-de-Datos-y-Machine-Learning-_files/figure-html/unnamed-chunk-70-2.png" width="672" /></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="modela.html#cb9-1" aria-hidden="true" tabindex="-1"></a>cm <span class="ot">&lt;-</span> predicted_data <span class="sc">%&gt;%</span> </span>
<span id="cb9-2"><a href="modela.html#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">est =</span> <span class="fu">factor</span>(<span class="fu">if_else</span>(.pred_Yes <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb9-3"><a href="modela.html#cb9-3" aria-hidden="true" tabindex="-1"></a>  yardstick<span class="sc">::</span><span class="fu">conf_mat</span>(<span class="at">truth =</span> truth, <span class="at">estimate =</span> est)</span>
<span id="cb9-4"><a href="modela.html#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="modela.html#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(cm, <span class="at">type =</span> <span class="st">&quot;heatmap&quot;</span>) <span class="sc">+</span></span>
<span id="cb9-6"><a href="modela.html#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Matriz de Confusión&quot;</span>) <span class="sc">+</span></span>
<span id="cb9-7"><a href="modela.html#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Verdaderos&quot;</span>) <span class="sc">+</span></span>
<span id="cb9-8"><a href="modela.html#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Predicciones&quot;</span>)</span></code></pre></div>
<p><img src="Taller-de--Introducci%C3%B3n-a-Ciencia-de-Datos-y-Machine-Learning-_files/figure-html/unnamed-chunk-70-3.png" width="672" /></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="modela.html#cb10-1" aria-hidden="true" tabindex="-1"></a>predicted_data <span class="sc">%&lt;&gt;%</span> </span>
<span id="cb10-2"><a href="modela.html#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">est =</span> <span class="fu">factor</span>(<span class="fu">if_else</span>(.pred_Yes <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>)))</span>
<span id="cb10-3"><a href="modela.html#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="modela.html#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_rows</span>(</span>
<span id="cb10-5"><a href="modela.html#cb10-5" aria-hidden="true" tabindex="-1"></a>  predicted_data <span class="sc">%&gt;%</span></span>
<span id="cb10-6"><a href="modela.html#cb10-6" aria-hidden="true" tabindex="-1"></a>  yardstick<span class="sc">::</span><span class="fu">precision</span>(truth, est, <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span>),</span>
<span id="cb10-7"><a href="modela.html#cb10-7" aria-hidden="true" tabindex="-1"></a>predicted_data <span class="sc">%&gt;%</span> </span>
<span id="cb10-8"><a href="modela.html#cb10-8" aria-hidden="true" tabindex="-1"></a>  yardstick<span class="sc">::</span><span class="fu">recall</span>(truth, est, <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span>),</span>
<span id="cb10-9"><a href="modela.html#cb10-9" aria-hidden="true" tabindex="-1"></a>predicted_data <span class="sc">%&gt;%</span> </span>
<span id="cb10-10"><a href="modela.html#cb10-10" aria-hidden="true" tabindex="-1"></a>  yardstick<span class="sc">::</span><span class="fu">accuracy</span>(truth, est, <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span>),</span>
<span id="cb10-11"><a href="modela.html#cb10-11" aria-hidden="true" tabindex="-1"></a>predicted_data <span class="sc">%&gt;%</span> </span>
<span id="cb10-12"><a href="modela.html#cb10-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_auc</span>(<span class="at">truth =</span> truth, <span class="at">estimatator =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span>),</span>
<span id="cb10-13"><a href="modela.html#cb10-13" aria-hidden="true" tabindex="-1"></a>predicted_data <span class="sc">%&gt;%</span> </span>
<span id="cb10-14"><a href="modela.html#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pr_auc</span>(<span class="at">truth =</span> truth, <span class="at">estimatator =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span>)</span>
<span id="cb10-15"><a href="modela.html#cb10-15" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 5 × 3
##   .metric   .estimator .estimate
##   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;
## 1 precision binary         0.617
## 2 recall    binary         0.472
## 3 accuracy  binary         0.780
## 4 roc_auc   binary         0.787
## 5 pr_auc    binary         0.593</code></pre>
<p>Comparemos los resultados de otros modelos:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="modela.html#cb12-1" aria-hidden="true" tabindex="-1"></a>results_cla_tree <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="at">file =</span> <span class="st">&#39;data/results_cla_tree.RDS&#39;</span>)</span>
<span id="cb12-2"><a href="modela.html#cb12-2" aria-hidden="true" tabindex="-1"></a>results_cla_rforest <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="at">file =</span> <span class="st">&#39;data/results_cla_rforest.RDS&#39;</span>)</span>
<span id="cb12-3"><a href="modela.html#cb12-3" aria-hidden="true" tabindex="-1"></a>results_cla_logistico <span class="ot">&lt;-</span> <span class="fu">readRDS</span>( <span class="at">file =</span> <span class="st">&#39;data/results_cla_logistico.RDS&#39;</span>)</span>
<span id="cb12-4"><a href="modela.html#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="modela.html#cb12-5" aria-hidden="true" tabindex="-1"></a>roc_curve_cla_tree <span class="ot">&lt;-</span> <span class="fu">roc_curve</span>(</span>
<span id="cb12-6"><a href="modela.html#cb12-6" aria-hidden="true" tabindex="-1"></a>  results_cla_tree, <span class="at">truth =</span> truth, <span class="at">estimate =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-7"><a href="modela.html#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="st">&#39;Árbol de decisión&#39;</span>)</span>
<span id="cb12-8"><a href="modela.html#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="modela.html#cb12-9" aria-hidden="true" tabindex="-1"></a>roc_curve_cla_random <span class="ot">&lt;-</span> <span class="fu">roc_curve</span>(</span>
<span id="cb12-10"><a href="modela.html#cb12-10" aria-hidden="true" tabindex="-1"></a>  results_cla_rforest, <span class="at">truth =</span> truth, <span class="at">estimate =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-11"><a href="modela.html#cb12-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="st">&#39;Random Forest&#39;</span>)</span>
<span id="cb12-12"><a href="modela.html#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="modela.html#cb12-13" aria-hidden="true" tabindex="-1"></a>roc_curve_cla_logistico <span class="ot">&lt;-</span> <span class="fu">roc_curve</span>(</span>
<span id="cb12-14"><a href="modela.html#cb12-14" aria-hidden="true" tabindex="-1"></a>  results_cla_logistico, <span class="at">truth =</span> Churn, <span class="at">estimate =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-15"><a href="modela.html#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="st">&#39;Logit&#39;</span>)</span>
<span id="cb12-16"><a href="modela.html#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="modela.html#cb12-17" aria-hidden="true" tabindex="-1"></a>pr_curve_cla_tree <span class="ot">&lt;-</span> <span class="fu">pr_curve</span>(</span>
<span id="cb12-18"><a href="modela.html#cb12-18" aria-hidden="true" tabindex="-1"></a>  results_cla_tree, <span class="at">truth =</span> truth, <span class="at">estimate =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-19"><a href="modela.html#cb12-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="st">&#39;Árbol de decisión&#39;</span>)</span>
<span id="cb12-20"><a href="modela.html#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="modela.html#cb12-21" aria-hidden="true" tabindex="-1"></a>pr_curve_cla_random <span class="ot">&lt;-</span> <span class="fu">pr_curve</span>(</span>
<span id="cb12-22"><a href="modela.html#cb12-22" aria-hidden="true" tabindex="-1"></a>  results_cla_rforest, <span class="at">truth =</span> truth, <span class="at">estimate =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-23"><a href="modela.html#cb12-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="st">&#39;Random Forest&#39;</span>)</span>
<span id="cb12-24"><a href="modela.html#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="modela.html#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="modela.html#cb12-26" aria-hidden="true" tabindex="-1"></a>pr_curve_cla_logistico <span class="ot">&lt;-</span> <span class="fu">pr_curve</span>(</span>
<span id="cb12-27"><a href="modela.html#cb12-27" aria-hidden="true" tabindex="-1"></a>  results_cla_logistico, <span class="at">truth =</span> Churn, <span class="at">estimate =</span> .pred_Yes, <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-28"><a href="modela.html#cb12-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="st">&#39;Logit&#39;</span>)</span>
<span id="cb12-29"><a href="modela.html#cb12-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-30"><a href="modela.html#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Pegamos id a los resultados de cada modelo</span></span>
<span id="cb12-31"><a href="modela.html#cb12-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-32"><a href="modela.html#cb12-32" aria-hidden="true" tabindex="-1"></a>results_pr_curve <span class="ot">&lt;-</span> <span class="fu">rbind</span>( pr_curve_cla_tree, pr_curve_cla_logistico, pr_curve_cla_random )</span>
<span id="cb12-33"><a href="modela.html#cb12-33" aria-hidden="true" tabindex="-1"></a>results_roc_curve <span class="ot">&lt;-</span> <span class="fu">rbind</span>(roc_curve_cla_tree,roc_curve_cla_logistico,roc_curve_cla_random)</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="modela.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Curvas pecision recall y ROC</span></span>
<span id="cb13-2"><a href="modela.html#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="modela.html#cb13-3" aria-hidden="true" tabindex="-1"></a>pr_curve_plot <span class="ot">&lt;-</span> results_pr_curve <span class="sc">%&gt;%</span></span>
<span id="cb13-4"><a href="modela.html#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> recall, <span class="at">y =</span> precision, <span class="at">color =</span> ID)) <span class="sc">+</span></span>
<span id="cb13-5"><a href="modela.html#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb13-6"><a href="modela.html#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb13-7"><a href="modela.html#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Precision vs Recall&quot;</span>) <span class="sc">+</span></span>
<span id="cb13-8"><a href="modela.html#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb13-9"><a href="modela.html#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="modela.html#cb13-10" aria-hidden="true" tabindex="-1"></a>roc_curve_plot <span class="ot">&lt;-</span> results_roc_curve <span class="sc">%&gt;%</span></span>
<span id="cb13-11"><a href="modela.html#cb13-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> specificity, <span class="at">y =</span> sensitivity, <span class="at">color =</span> ID)) <span class="sc">+</span></span>
<span id="cb13-12"><a href="modela.html#cb13-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb13-13"><a href="modela.html#cb13-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>() <span class="sc">+</span></span>
<span id="cb13-14"><a href="modela.html#cb13-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb13-15"><a href="modela.html#cb13-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROC Curve&quot;</span>) <span class="sc">+</span></span>
<span id="cb13-16"><a href="modela.html#cb13-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb13-17"><a href="modela.html#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="modela.html#cb13-18" aria-hidden="true" tabindex="-1"></a>pr_curve_plot </span></code></pre></div>
<p><img src="Taller-de--Introducci%C3%B3n-a-Ciencia-de-Datos-y-Machine-Learning-_files/figure-html/unnamed-chunk-72-1.png" width="672" /></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="modela.html#cb14-1" aria-hidden="true" tabindex="-1"></a>roc_curve_plot</span></code></pre></div>
<p><img src="Taller-de--Introducci%C3%B3n-a-Ciencia-de-Datos-y-Machine-Learning-_files/figure-html/unnamed-chunk-72-2.png" width="672" /></p>
</div>
</div>
<div id="algotitmos-de-machine-learning" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Algotitmos de machine learning</h2>
<p>Hasta este momento, se ha aprendido cuáles son las métricas más utilizadas para la evaluación de modelos de machine learning, así como la importancia del problema, contexto a resolver y en qué casos una métrica algunas métricas son más relevantes que otras. Apendimos también a interpretar el <em>trade-off</em> entre distintas métricas para tomar decisiones adecuadas a nuestros recursos disponibles.</p>
<p>Ahora, se conocerá la estructura e idea general de algoritmos que son frecuentemente usados en la industria.</p>
<p><img src="img/ml/models.png" width="700pt" height="400pt" style="display: block; margin: auto;" /></p>
<div id="regresión-logística" class="section level3" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Regresión logística</h3>
<p>En esta sección aprenderemos sobre regresión logística. Existen dos tipos de modelos de regresión logística: regresión simple y regresión múltiple. La regresión logística simple es cuando se utiliza <strong>una</strong> variable independiente para <strong>estimar la probabilidad de pertenecer a un grupo de una variable cualitativa binaria</strong>. Cuando se utiliza <strong>más de una</strong> variable independiente, el proceso se denomina regresión logística múltiple.</p>
<div id="función-sigmoide" class="section level4" number="5.6.1.1">
<h4><span class="header-section-number">5.6.1.1</span> Función sigmoide</h4>
<p>Si una variable cualitativa con dos categorías se codifica como 1 y 0, matemáticamente es posible ajustar un modelo de regresión lineal por mínimos cuadrados. El problema de esta aproximación es que, al tratarse de una recta, para valores extremos del predictor, se obtienen valores de <span class="math inline">\(Y\)</span> menores que 0 o mayores que 1, lo que entra en contradicción con el hecho de que las probabilidades siempre están dentro del rango [0,1].</p>
<p>Para evitar estos problemas, la regresión logística transforma el valor devuelto por la regresión lineal empleando una función cuyo resultado está siempre comprendido entre 0 y 1. Existen varias funciones que cumplen esta descripción, una de las más utilizadas es la función logística (también conocida como función <strong>sigmoide</strong>):</p>
<p><span class="math display">\[\sigma(x)=\frac{1}{1+e^{-x}}\]</span>
Función sigmoide:</p>
<p><img src="img/ml/3-8-1-sigmoide.png" width="300pt" height="300pt" style="display: block; margin: auto;" />
Para valores de <span class="math inline">\(x\)</span> muy grandes, el valor de <span class="math inline">\(e^{-x}\)</span> es aproximadamente 0 por lo que el valor de la función sigmoide es 1. Para valores de <span class="math inline">\(x\)</span> muy negativos, el valor <span class="math inline">\(e^{-x}\)</span> tiende a infinito por lo que el valor de la función sigmoide es 0.</p>
<p>Sustituyendo la <span class="math inline">\(x\)</span> de la función sigmoide por la función lineal <span class="math inline">\(\beta_0+\beta_1X\)</span> se obtiene que:</p>
<p><span class="math display">\[P(Y=k|X=x)=\frac{e^{\beta_0+\beta_1X}}{1+e^{\beta_0+\beta_1X}}\]</span></p>
<p>donde <span class="math inline">\(P(Y=k|X=x)\)</span> puede interpretarse como: la probabilidad de que la variable cualitativa <span class="math inline">\(Y\)</span> adquiera el valor <span class="math inline">\(k\)</span>, dado que el predictor <span class="math inline">\(X\)</span> tiene el valor <span class="math inline">\(x\)</span>.</p>
<p>Esta función, puede ajustarse de forma sencilla con métodos de regresión lineal si se emplea su versión logarítmica:</p>
<p><span class="math display">\[ln(\frac{p(Y=k|X=x)}{1−p(Y=k|X=x)})=\beta_0+\beta_1X\]</span></p>
</div>
</div>
<div id="knn-k-nearest-neighbor" class="section level3" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> KNN: K-Nearest-Neighbor</h3>
<p>KNN es un algoritmo de aprendizaje supervisado que podemos usar para regresión o clasificación.</p>
<p>La idea detrás del algoritmo es sencilla, este clasifica una nueva observación en la categoria que tenga mas elementos de las k observaciones más cercanas. Es decir, se calculará la distancia de esta nueva observación a cada observación existente, ordenaremos estas distancias de menor a mayor, tomamos las k primeras distancias, la nueva observación sera asignada al grupo que tenga mayor número de observaciones en estas k primeras distancias.</p>
<p><strong>Clasificación</strong></p>
<p>¿Cómo debería ser clasificada la nueva observación?</p>
<p><img src="img/ml/3-10-1-knn-clasificacion.png" width="700pt" height="500pt" style="display: block; margin: auto;" /></p>
<p><img src="img/ml/3-10-1-knn-all.png" width="700pt" height="500pt" style="display: block; margin: auto;" /></p>
<p><strong>Ejemplo:</strong></p>
<p><img src="img/ml/3-10-1-knn-clasificacion2.png" width="700pt" height="500pt" style="display: block; margin: auto;" /></p>
<p><strong>Regresión:</strong></p>
<p>Considerando un modelo de 3 vecinos más cercanos, las siguientes imágenes muestran el proceso de ajuste y predicción de nuevas observaciones.</p>
<p><img src="img/ml/3-10-1-regression1.png" width="350pt" height="300pt" /><img src="img/ml/3-10-1-regression2.png" width="350pt" height="300pt" /></p>
<p><img src="img/ml/3-10-1-regression3.png" width="350pt" height="300pt" style="display: block; margin: auto;" /></p>
<p><strong>Ejemplo de balance de sesgo y varianza</strong></p>
<p><img src="img/ml/3-10-1-knn-regresion2.png" width="700pt" height="500pt" style="display: block; margin: auto;" /></p>
</div>
<div id="árboles-de-decisión-decision-trees" class="section level3" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> Árboles de decisión (Decision trees)</h3>
<p><img src="img/ml/3-11-0-arboles.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<p>Un árbol de decisiones es un algoritmo del aprendizaje supervisado que se puede utilizar tanto para problemas de <strong>clasificación</strong> como de <strong>regresión</strong>. Es un clasificador estructurado en árbol, donde los nodos internos representan las características de un conjunto de datos, las ramas representan las reglas de decisión y cada nodo hoja representa el resultado. La idea básica de los árboles es buscar puntos de cortes en las variables de entrada para hacer predicciones, ir dividiendo la muestra, y encontrar cortes sucesivos para refinar las predicciones.</p>
<p>En un árbol de decisión, hay dos tipos nodos, el nodo de decisión o nodos internos (Decision Node) y el nodo hoja o nodo terminal (Leaf node). Los nodos de decisión se utilizan para tomar cualquier decisión y tienen múltiples ramas, mientras que los nodos hoja son el resultado de esas decisiones y no contienen más ramas.</p>
<p><img src="img/ml/3-11-1-arboles.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<ul>
<li>Regresión:</li>
</ul>
<p><img src="img/ml/3-11-arbol-reg-graph.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<p><img src="img/ml/3-11-arbol-reg-diagram.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<ul>
<li>Clasificación:</li>
</ul>
<p><img src="img/ml/3-11-arbol-cla-graph.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<p><img src="img/ml/3-11-arbol-cla-diagram.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<p><img src="img/ml/3-11-1-ejemploreg.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
</div>
<div id="bagging" class="section level3" number="5.6.4">
<h3><span class="header-section-number">5.6.4</span> Bagging</h3>
<p>Primero tenemos que definir qué es la ** Agregación de Bootstrap o Bagging**. Este es un aalgoritmo de aprendizaje automático diseñado para mejorar la estabilidad y precisión de algoritmos de ML usados en clasificación estadística y regresión. Además reduce la varianza y ayuda a evitar el sobreajuste. Aunque es usualmente aplicado a métodos de árboles de decisión, puede ser usado con cualquier tipo de método. Bagging es un caso especial del promediado de modelos.</p>
<p>Los métodos de bagging son métodos donde los algoritmos simples son usados en paralelo. El principal objetivo de los métodos en paralelo es el de aprovecharse de la independencia que hay entre los algoritmos simples, ya que el error se puede reducir bastante al promediar las salidas de los modelos simples. Es como si, queriendo resolver un problema entre varias personas independientes unas de otras, damos por bueno lo que eligiese la mayoría de las personas.</p>
<p>Para obtener la agregación de las salidas de cada modelo simple e independiente, bagging puede usar la votación para los métodos de clasificiación y el promedio para los métodos de regresión.</p>
<p><img src="img/ml/3-12-1-bag.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
</div>
<div id="random-forest" class="section level3" number="5.6.5">
<h3><span class="header-section-number">5.6.5</span> Random Forest</h3>
<p>Un bosque aleatorio es un algoritmo de aprendizaje automático supervisado que se
construye a partir de algoritmos de árbol de decisión. Este algoritmo se aplica
en diversas industrias, como la banca y el comercio electrónico, para predecir el comportamiento y los resultados.</p>
<p>En esta clase se dará una descripción general del algoritmo de bosque aleatorio,
cómo funciona y las características del algoritmo.</p>
<p>También se señalan las ventajas y desventajas de este algoritmo.</p>
<p><strong>¿Qué es?</strong></p>
<p>Un bosque aleatorio es una técnica de aprendizaje automático que se utiliza
para resolver problemas de regresión y clasificación. Utiliza el aprendizaje por
conjuntos, que es una técnica que combina muchos clasificadores para proporcionar
soluciones a problemas complejos.</p>
<p>Este algoritmo consta de muchos árboles de decisión. El “bosque” generado se entrena
mediante <strong>agregación de bootstrap (bagging)</strong>, el cual es es un meta-algoritmo
de conjunto que mejora la precisión de los algoritmos de aprendizaje automático.</p>
<p>El algoritmo establece el resultado en función de las predicciones de los
árboles de decisión. Predice tomando el promedio o la media de la salida de
varios árboles. El aumento del número de árboles aumenta la precisión del resultado.</p>
<p>Un bosque aleatorio erradica las limitaciones de un algoritmo de árbol de decisión.
Reduce el sobreajuste de conjuntos de datos y aumenta la precisión.</p>
<p><img src="img/ml/3-10-1-bosques-aleatorios.png" width="600pt" height="300pt" style="display: block; margin: auto;" /></p>
<div id="características-de-los-bosques-aleatorios" class="section level4" number="5.6.5.1">
<h4><span class="header-section-number">5.6.5.1</span> Características de los bosques aleatorios</h4>
<ul>
<li><p>Es más preciso que el algoritmo árbol de decisiones.</p></li>
<li><p>Proporciona una forma eficaz de gestionar los datos faltantes.</p></li>
<li><p>Puede producir una predicción razonable sin ajuste de hiperparámetros.</p></li>
<li><p>Resuelve el problema del sobreajuste en los árboles de decisión.</p></li>
<li><p>En cada árbol forestal aleatorio, se selecciona aleatoriamente un subconjunto
de características en el punto de división del nodo.</p></li>
</ul>
</div>
<div id="aplicar-árboles-de-decisión-en-un-bosque-aleatorio" class="section level4" number="5.6.5.2">
<h4><span class="header-section-number">5.6.5.2</span> Aplicar árboles de decisión en un bosque aleatorio</h4>
<p><strong>La principal diferencia entre el algoritmo de árbol de decisión y el algoritmo de bosque aleatorio es que</strong> el establecimiento de nodos raíz y la desagregación de
nodos se realiza de forma aleatoria en este último. <strong>El bosque aleatorio emplea el método de bagging para generar la predicción requerida.</strong></p>
<p><strong>El método bagging implica el uso de diferentes muestras de datos (datos de entrenamiento) en lugar de una sola muestra.</strong> Los árboles de decisión producen diferentes resultados, dependiendo de los datos de entrenamiento alimentados al
algoritmo de bosque aleatorio. Estos resultados se clasificarán y se seleccionará
el más alto como resultado final.</p>
<p>Nuestro primer ejemplo todavía se puede utilizar para explicar cómo funcionan los bosques aleatorios. Supongamos que solo tenemos cuatro árboles de decisión. En este caso, los datos de entrenamiento que comprenden las observaciones y funciones del teléfono se dividirán en cuatro nodos raíz.</p>
<p>Los nodos raíz podrían representar cuatro características que podrían influir en la elección del cliente (precio, almacenamiento interno, cámara y RAM). <strong>El bosque aleatorio dividirá los nodos seleccionando características al azar. La predicción final se seleccionará en función del resultado de los cuatro árboles.</strong></p>
<p><strong>El resultado elegido por la mayoría de los árboles de decisión será la elección final.</strong></p>
<p>Si tres árboles predicen la compra y un árbol predice que no comprará, entonces la predicción final será la compra. En este caso, se prevé que el cliente comprará el teléfono.</p>
<p>El siguiente diagrama muestra un clasificador de bosque aleatorio simple.</p>
<p><img src="img/ml/randomforest_ejemplo.jpg" width="700pt" height="400pt" style="display: block; margin: auto;" /></p>
<p><img src="img/ml/3-13-1-randomforest.png" width="600pt" height="300pt" style="display: block; margin: auto;" /></p>
</div>
<div id="ventajas-y-desventajas-de-bosques-aleatorios" class="section level4" number="5.6.5.3">
<h4><span class="header-section-number">5.6.5.3</span> Ventajas y desventajas de bosques aleatorios</h4>
<p><strong>Ventajas</strong></p>
<ul>
<li><p>Puede realizar tareas de regresión y clasificación.</p></li>
<li><p>Un bosque aleatorio produce buenas predicciones que se pueden entender fácilmente.</p></li>
<li><p>Puede manejar grandes conjuntos de datos de manera eficiente.</p></li>
<li><p>Proporciona un mayor nivel de precisión en la predicción de resultados sobre el algoritmo del árbol de decisión.</p></li>
</ul>
<p><strong>Desventajas</strong></p>
<ul>
<li><p>Cuando se usa un bosque aleatorio, se requieren bastantes recursos para el cálculo.</p></li>
<li><p>Consume más tiempo en comparación con un algoritmo de árbol de decisiones.</p></li>
<li><p>No producen buenos resultados cuando los datos son muy escasos. En este caso,
el subconjunto de características y la muestra de arranque producirán un espacio invariante. Esto conducirá a divisiones improductivas, que afectarán el resultado.</p></li>
</ul>

</div>
</div>
</div>
</div>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script>

$('.pipehover_incremental tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).prevAll().addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});


$('.pipehover_select_one_row tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});

</script>
            </section>

          </div>
        </div>
      </div>
<a href="explora.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="muestreo.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Taller de  Introducción a Ciencia de Datos y Machine Learning .pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
